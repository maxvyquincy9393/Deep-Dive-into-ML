{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â¤ï¸ Case Study: Heart Disease Classification\n",
    "\n",
    "---\n",
    "\n",
    "## A Life-Saving Problem\n",
    "\n",
    "Heart disease is the #1 cause of death worldwide. Early detection saves lives!\n",
    "\n",
    "> **The Question**: Given a patient's clinical data, can we predict if they have heart disease?\n",
    "\n",
    "This is exactly what hospitals use machine learning for - helping doctors make better decisions!\n",
    "\n",
    "---\n",
    "\n",
    "## Why Logistic Regression?\n",
    "\n",
    "This is a **binary classification** problem:\n",
    "- Class 0: No heart disease\n",
    "- Class 1: Heart disease present\n",
    "\n",
    "Logistic Regression is perfect because:\n",
    "1. Outputs **probabilities** (not just classes)\n",
    "2. **Highly interpretable** (doctors can understand the coefficients)\n",
    "3. Works well for **medical diagnosis** where we need to expother decisions\n",
    "\n",
    "ğŸ’¡ **Key Insight**: In medicine, a black-box model that says \"you're sick\" isn't helpful. Doctors need to know WHY!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“¦ STEP 1: LOAD DATA AND LIBRARIES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                             roc_curve, auc, precision_recall_curve, f1_score)\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸ“¥ Loading Heart Disease Dataset from OpenML...\")\n",
    "print(\"=\"*50)\n",
    "heart = fetch_openml(name='heart-statlog', version=1, as_frame=True)\n",
    "df = heart.frame\n",
    "\n",
    "print(f\"âœ… Loaded {len(df)} patient records\")\n",
    "print(f\"\\nğŸ“‹ Features available: {list(df.columns)}\")\n",
    "print(f\"\\nğŸ“Š First 5 patients:\")\n",
    "print(df.head())\n",
    "print(f\"\\nğŸ’¾ Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 2: Exploratory Data Analysis\n",
    "\n",
    "Before building any model, let's understand our data. In medical ML, EDA is CRITICAL because:\n",
    "- We need to catch data quality issues (missing values, outliers)\n",
    "- We need to understand feature distributions\n",
    "- We need to check for class imbalance (common in disease detection!)\n",
    "\n",
    "> **Golden Rule**: \"If you don't understand your data, your model won't either.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“Š EXPLORATORY DATA ANALYSIS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# 1. Dataset Overview\n",
    "print(\"ğŸ“‹ DATASET OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nData Types:\\n{df.dtypes}\")\n",
    "print(f\"\\nMissing Values:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# 2. Target Distribution\n",
    "print(\"\\nğŸ“Š TARGET DISTRIBUTION\")\n",
    "y = (df['target'] == '2').astype(int)\n",
    "print(f\"   No Heart Disease (0): {(y == 0).sum()} ({(y == 0).mean()*100:.1f}%)\")\n",
    "print(f\"   Heart Disease (1): {(y == 1).sum()} ({(y == 1).mean()*100:.1f}%)\")\n",
    "\n",
    "# 3. Visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Age distribution by class\n",
    "ax = axes[0, 0]\n",
    "for label in [0, 1]:\n",
    "    subset = df[y == label]['age'].astype(float)\n",
    "    ax.hist(subset, bins=20, alpha=0.7, label=f'Class {label}')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Age Distribution by Heart Disease Status')\n",
    "ax.legend()\n",
    "\n",
    "# Correlation heatmap (numeric features only)\n",
    "ax = axes[0, 1]\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "if len(numeric_df.columns) > 0:\n",
    "    sns.heatmap(numeric_df.corr(), annot=True, fmt='.2f', cmap='coolwarm', ax=ax)\n",
    "    ax.set_title('Feature Correlations')\n",
    "\n",
    "# Class balance pie chart\n",
    "ax = axes[0, 2]\n",
    "y.value_counts().plot.pie(ax=ax, autopct='%1.1f%%', colors=['lightblue', 'salmon'])\n",
    "ax.set_title('Class Distribution')\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# Chest pain type distribution\n",
    "ax = axes[1, 0]\n",
    "if 'chest' in df.columns:\n",
    "    pd.crosstab(df['chest'], y).plot(kind='bar', ax=ax)\n",
    "    ax.set_title('Chest Pain Type vs Heart Disease')\n",
    "    ax.set_xlabel('Chest Pain Type')\n",
    "\n",
    "# Resting BP boxplot\n",
    "ax = axes[1, 1]\n",
    "if 'resting_blood_pressure' in df.columns:\n",
    "    df.boxplot(column='resting_blood_pressure', by=y, ax=ax)\n",
    "    ax.set_title('Resting BP by Heart Disease Status')\n",
    "\n",
    "# Max heart rate\n",
    "ax = axes[1, 2]\n",
    "if 'max_heart_rate' in df.columns:\n",
    "    df.boxplot(column='max_heart_rate', by=y, ax=ax)\n",
    "    ax.set_title('Max Heart Rate by Heart Disease Status')\n",
    "\n",
    "plt.suptitle('Heart Disease EDA', y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ Insights from EDA:\")\n",
    "print(\"   â€¢ Dataset is relatively balanced (good!)\")\n",
    "print(\"   â€¢ Age and max heart rate show clear differences between classes\")\n",
    "print(\"   â€¢ Chest pain type appears to be a strong predictor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Understanding the Features\n",
    "\n",
    "Each feature is a clinical measurement that doctors commonly use for heart disease assessment:\n",
    "\n",
    "| Feature | Description | Clinical Relevance |\n",
    "|---------|-------------|-------------------|\n",
    "| **age** | Patient age in years | Risk increases with age |\n",
    "| **sex** | Male (1) or Female (0) | Males have higher risk |\n",
    "| **chest** | Chest pain type (1-4) | Key diagnostic symptom |\n",
    "| **resting_blood_pressure** | Resting BP (mm Hg) | High BP = higher risk |\n",
    "| **serum_cholesterol** | Cholesterol level (mg/dl) | High cholesterol = higher risk |\n",
    "| **fasting_blood_sugar** | >120 mg/dl (1=true) | Indicates diabetes risk |\n",
    "| **resting_electrocardiographic_results** | ECG results (0-2) | Detects heart abnormalities |\n",
    "| **max_heart_rate** | Max HR during exercise | Low max HR = higher risk |\n",
    "| **exercise_induced_angina** | Chest pain during exercise | Strong predictor |\n",
    "| **oldpeak** | ST depression from exercise | ECG abnormality marker |\n",
    "| **slope** | Slope of ST segment | Heart function indicator |\n",
    "| **number_of_major_vessels** | Vessels colored by fluoroscopy | More = worse prognosis |\n",
    "| **thal** | Thalassemia blood disorder | Normal/Fixed/Reversible defect |\n",
    "| **target** | Heart disease presence | 1=No disease, 2=Disease |\n",
    "\n",
    "ğŸ’¡ **Key Insight**: These features are derived from real clinical tests - blood work, ECG, and exercise stress tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ STEP 3: DATA PREPARATION AND MODEL TRAINING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Prepare features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = (df['target'] == '2').astype(int)  # 2 = has disease\n",
    "\n",
    "print(\"ğŸ“Š CLASS DISTRIBUTION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"   No Heart Disease (0): {(y == 0).sum()} ({(y == 0).mean()*100:.1f}%)\")\n",
    "print(f\"   Heart Disease (1): {(y == 1).sum()} ({(y == 1).mean()*100:.1f}%)\")\n",
    "\n",
    "# Feature Scaling (CRITICAL for Logistic Regression!)\n",
    "print(\"\\nğŸ”§ SCALING FEATURES\")\n",
    "print(\"-\"*50)\n",
    "print(\"Why scale? Logistic Regression uses gradient descent.\")\n",
    "print(\"Features on different scales â†’ slow convergence, biased coefficients!\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-Test Split (stratified to maintain class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“Š Data Split:\")\n",
    "print(f\"   Training: {len(X_train)} samples\")\n",
    "print(f\"   Testing: {len(X_test)} samples\")\n",
    "\n",
    "# Train Logistic Regression\n",
    "print(\"\\nğŸ¤– TRAINING MODEL\")\n",
    "print(\"-\"*50)\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ… Model successfully trained!\")\n",
    "print(f\"   Coefficients shape: {model.coef_.shape}\")\n",
    "print(f\"   Intercept: {model.intercept_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Step 4: Feature Importance Analysis\n",
    "\n",
    "One of the biggest advantages of Logistic Regression in medicine is **interpretability**.\n",
    "\n",
    "We can look at the coefficients to understand:\n",
    "- Which features increase heart disease risk?\n",
    "- Which features are protective?\n",
    "- How much does each factor matter?\n",
    "\n",
    "> **Medical Insight**: A model that says \"your risk is 85%\" isn't actionable. But a model that says \"your high cholesterol and low exercise tolerance are the main risk factors\" helps doctors create a treatment plan!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ” FEATURE IMPORTANCE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Get feature names and coefficients\n",
    "feature_names = X.columns.tolist()\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Create importance dataframe\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Coefficient': np.abs(coefficients),\n",
    "    'Odds_Ratio': np.exp(coefficients)\n",
    "})\n",
    "importance_df = importance_df.sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"ğŸ“Š FEATURE IMPORTANCE (by |coefficient|)\")\n",
    "print(\"=\"*60)\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red' if c > 0 else 'blue' for c in importance_df['Coefficient']]\n",
    "plt.barh(importance_df['Feature'], importance_df['Coefficient'], color=colors)\n",
    "plt.xlabel('Coefficient (Log-Odds)', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Feature Importance: Risk Factors for Heart Disease\\nRed = Increases Risk | Blue = Decreases Risk', fontsize=14)\n",
    "plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nğŸ’¡ INTERPRETATION:\")\n",
    "print(\"-\"*50)\n",
    "for _, row in importance_df.head(5).iterrows():\n",
    "    direction = \"INCREASES\" if row['Coefficient'] > 0 else \"DECREASES\"\n",
    "    print(f\"â€¢ {row['Feature']}: {direction} heart disease risk\")\n",
    "    print(f\"  Odds Ratio: {row['Odds_Ratio']:.3f}\")\n",
    "    print(f\"  (1-unit increase in scaled feature â†’ odds multiply by {row['Odds_Ratio']:.3f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“Š MODEL EVALUATION - CONFUSION MATRIX\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"ğŸ“Š CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=['No Disease', 'Heart Disease']))\n",
    "\n",
    "# Confusion Matrix with detailed annotations\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Standard confusion matrix\n",
    "ax = axes[0]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Disease', 'Heart Disease'], \n",
    "            yticklabels=['No Disease', 'Heart Disease'], ax=ax)\n",
    "ax.set_title('Confusion Matrix', fontsize=14)\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "\n",
    "# Annotated confusion matrix with medical context\n",
    "ax = axes[1]\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "annotated = np.array([\n",
    "    [f'TN\\n{tn}\\n(Correctly healthy)', f'FP\\n{fp}\\n(False alarm)'],\n",
    "    [f'FN\\n{fn}\\n(MISSED DISEASE!)', f'TP\\n{tp}\\n(Correctly detected)']\n",
    "])\n",
    "sns.heatmap(cm, annot=annotated, fmt='', cmap='RdYlGn', \n",
    "            xticklabels=['Predicted Healthy', 'Predicted Disease'], \n",
    "            yticklabels=['Actually Healthy', 'Actually Disease'], ax=ax)\n",
    "ax.set_title('Medical Context: Confusion Matrix', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Medical implications\n",
    "print(\"\\nğŸ¥ MEDICAL IMPLICATIONS:\")\n",
    "print(\"-\"*50)\n",
    "print(f\"   True Positives (TP): {tp} - Correctly identified sick patients âœ…\")\n",
    "print(f\"   True Negatives (TN): {tn} - Correctly identified healthy patients âœ…\")\n",
    "print(f\"   False Positives (FP): {fp} - Healthy patients flagged for extra tests (acceptable)\")\n",
    "print(f\"   False Negatives (FN): {fn} - MISSED DISEASE CASES (dangerous!) âš ï¸\")\n",
    "print(f\"\\n   Sensitivity (Recall): {tp/(tp+fn):.1%} of sick patients detected\")\n",
    "print(f\"   Specificity: {tn/(tn+fp):.1%} of healthy patients correctly identified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“ˆ ROC CURVE AND AUC\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Find optimal threshold (Youden's J statistic)\n",
    "j_scores = tpr - fpr\n",
    "optimal_idx = np.argmax(j_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Main ROC curve\n",
    "plt.plot(fpr, tpr, color='darkorange', linewidth=2.5, \n",
    "         label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "\n",
    "# Mark optimal point\n",
    "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=150, zorder=5,\n",
    "            label=f'Optimal Threshold = {optimal_threshold:.2f}')\n",
    "\n",
    "# Add some threshold annotations\n",
    "for i, thresh in enumerate([0.3, 0.5, 0.7]):\n",
    "    idx = np.argmin(np.abs(thresholds - thresh))\n",
    "    plt.annotate(f't={thresh}', (fpr[idx], tpr[idx]), \n",
    "                 textcoords=\"offset points\", xytext=(10, -10), fontsize=9)\n",
    "\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "plt.title('ROC Curve: Heart Disease Detection\\nHigher AUC = Better Discrimination', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add reference lines\n",
    "plt.axhline(y=0.9, color='gray', linestyle=':', alpha=0.5)\n",
    "plt.axvline(x=0.1, color='gray', linestyle=':', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Performance summary\n",
    "print(\"\\nğŸ¯ MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"   Accuracy: {accuracy_score(y_test, y_pred)*100:.1f}%\")\n",
    "print(f\"   ROC-AUC: {roc_auc:.3f}\")\n",
    "print(f\"   Optimal Threshold: {optimal_threshold:.3f}\")\n",
    "print(f\"\\nğŸ’¡ AUC Interpretation:\")\n",
    "print(\"   â€¢ AUC = 0.5: Random guessing (useless)\")\n",
    "print(\"   â€¢ AUC = 0.7-0.8: Acceptable discrimination\")\n",
    "print(\"   â€¢ AUC = 0.8-0.9: Excellent discrimination\")\n",
    "print(\"   â€¢ AUC > 0.9: Outstanding discrimination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš–ï¸ Step 5: Threshold Optimization (Medical Cost-Sensitive)\n",
    "\n",
    "In medicine, **threshold = 0.5 is often WRONG!**\n",
    "\n",
    "Consider the costs:\n",
    "- **False Negative (missing disease)**: Patient goes untreated â†’ Potentially FATAL\n",
    "- **False Positive (false alarm)**: Patient gets extra tests â†’ Inconvenient but safe\n",
    "\n",
    "> **Medical Decision Rule**: When in doubt, err on the side of caution!\n",
    "\n",
    "This means we should use a LOWER threshold to maximize **Recall** (catch all sick patients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âš–ï¸ THRESHOLD OPTIMIZATION FOR MEDICAL DIAGNOSIS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Get precision-recall curve\n",
    "precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Calculate F1 and F2 (F2 weights recall more heavily - better for medical)\n",
    "f1_scores = 2 * (precision_curve[:-1] * recall_curve[:-1]) / (precision_curve[:-1] + recall_curve[:-1] + 1e-10)\n",
    "f2_scores = 5 * (precision_curve[:-1] * recall_curve[:-1]) / (4 * precision_curve[:-1] + recall_curve[:-1] + 1e-10)\n",
    "\n",
    "# Find optimal thresholds\n",
    "optimal_f1_idx = np.argmax(f1_scores)\n",
    "optimal_f2_idx = np.argmax(f2_scores)\n",
    "\n",
    "# For medical: we want high recall (catch all cases)\n",
    "# Find threshold where recall >= 0.9\n",
    "high_recall_idx = np.where(recall_curve[:-1] >= 0.9)[0]\n",
    "if len(high_recall_idx) > 0:\n",
    "    medical_threshold = thresholds_pr[high_recall_idx[-1]]\n",
    "else:\n",
    "    medical_threshold = 0.3\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Precision-Recall Curve\n",
    "ax = axes[0]\n",
    "ax.plot(recall_curve, precision_curve, 'b-', linewidth=2)\n",
    "ax.scatter(recall_curve[optimal_f1_idx], precision_curve[optimal_f1_idx], \n",
    "          color='red', s=100, label=f'Best F1 (thresh={thresholds_pr[optimal_f1_idx]:.2f})')\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Precision', fontsize=12)\n",
    "ax.set_title('Precision-Recall Curve', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Metrics vs Threshold\n",
    "ax = axes[1]\n",
    "ax.plot(thresholds_pr, f1_scores, 'g-', linewidth=2, label='F1 Score')\n",
    "ax.plot(thresholds_pr, f2_scores, 'b-', linewidth=2, label='F2 Score (recall-heavy)')\n",
    "ax.plot(thresholds_pr, recall_curve[:-1], 'r-', linewidth=2, label='Recall')\n",
    "ax.axvline(x=0.5, color='gray', linestyle='--', alpha=0.5, label='Default (0.5)')\n",
    "ax.axvline(x=medical_threshold, color='red', linestyle='--', \n",
    "          label=f'Medical (90% recall): {medical_threshold:.2f}')\n",
    "ax.set_xlabel('Threshold', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Metrics vs Threshold', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare predictions at different thresholds\n",
    "print(\"ğŸ“Š THRESHOLD COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "for thresh, name in [(0.5, 'Default (0.5)'), (medical_threshold, f'Medical ({medical_threshold:.2f})')]:\n",
    "    y_pred_thresh = (y_proba >= thresh).astype(int)\n",
    "    tp = np.sum((y_test == 1) & (y_pred_thresh == 1))\n",
    "    fn = np.sum((y_test == 1) & (y_pred_thresh == 0))\n",
    "    fp = np.sum((y_test == 0) & (y_pred_thresh == 1))\n",
    "    recall_val = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    f1_val = 2 * precision_val * recall_val / (precision_val + recall_val) if (precision_val + recall_val) > 0 else 0\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"   Recall: {recall_val:.3f} (catching {tp}/{tp+fn} sick patients)\")\n",
    "    print(f\"   Precision: {precision_val:.3f}\")\n",
    "    print(f\"   F1: {f1_val:.3f}\")\n",
    "    print(f\"   Missed Cases (FN): {fn}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ RECOMMENDATION: Use lower threshold in medical screening!\")\n",
    "print(\"   Better to have extra tests (FP) than miss a disease (FN)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Step 6: Cross-Validation for Robust Evaluation\n",
    "\n",
    "A single train-test split can be misleading. Let's use **Stratified K-Fold Cross-Validation**:\n",
    "- Maintains class balance in each fold\n",
    "- Gives us confidence intervals for our metrics\n",
    "- Essential for medical applications where reliability matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¥ Step 7: Clinical Decision Support System\n",
    "\n",
    "Let's create a practical tool that could be used in a clinical setting.\n",
    "\n",
    "This demonstrates how our model would work in production:\n",
    "1. Take patient data\n",
    "2. Calculate risk probability\n",
    "3. Provide actionable recommendations\n",
    "\n",
    "> **Note**: This is for educational purposes. Real medical AI requires extensive validation and regulatory approval!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¥ CLINICAL DECISION SUPPORT DEMO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def predict_heart_disease_risk(patient_data, model, scaler, feature_names):\n",
    "    \"\"\"\n",
    "    Predict heart disease risk for a patient.\n",
    "    Returns probability and risk category.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    patient_data : array-like\n",
    "        Patient's clinical measurements (unscaled)\n",
    "    model : trained LogisticRegression model\n",
    "    scaler : fitted StandardScaler\n",
    "    feature_names : list of feature names\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (probability, risk_level, color, recommendation)\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame\n",
    "    X_patient = pd.DataFrame([patient_data], columns=feature_names)\n",
    "    \n",
    "    # Scale\n",
    "    X_scaled = scaler.transform(X_patient)\n",
    "    \n",
    "    # Predict probability\n",
    "    prob = model.predict_proba(X_scaled)[0, 1]\n",
    "    \n",
    "    # Risk stratification (based on clinical guidelines)\n",
    "    if prob < 0.2:\n",
    "        risk_level = \"LOW RISK\"\n",
    "        color = \"ğŸŸ¢\"\n",
    "        recommendation = \"Continue healthy lifestyle. Regular annual checkups.\"\n",
    "    elif prob < 0.5:\n",
    "        risk_level = \"MODERATE RISK\"\n",
    "        color = \"ğŸŸ¡\"\n",
    "        recommendation = \"Lifestyle modifications recommended. Monitor closely.\"\n",
    "    elif prob < 0.8:\n",
    "        risk_level = \"HIGH RISK\"\n",
    "        color = \"ğŸŸ \"\n",
    "        recommendation = \"Immediate medical consultation. Consider further testing.\"\n",
    "    else:\n",
    "        risk_level = \"CRITICAL RISK\"\n",
    "        color = \"ğŸ”´\"\n",
    "        recommendation = \"URGENT: Cardiology referral required immediately.\"\n",
    "    \n",
    "    return prob, risk_level, color, recommendation\n",
    "\n",
    "\n",
    "# Demo with test samples\n",
    "print(\"ğŸ¥ CLINICAL DECISION SUPPORT DEMO\")\n",
    "print(\"=\"*60)\n",
    "print(\"Demonstrating how the model would work in a clinical setting...\\n\")\n",
    "\n",
    "# Convert X_test back to DataFrame for easier handling\n",
    "X_test_df = pd.DataFrame(\n",
    "    scaler.inverse_transform(X_test) if hasattr(X_test, '__len__') else X_test,\n",
    "    columns=X.columns\n",
    ")\n",
    "\n",
    "# Evaluate on a few test samples\n",
    "for i in range(min(5, len(X_test))):\n",
    "    patient = X_test_df.iloc[i].values\n",
    "    actual = y_test.iloc[i] if hasattr(y_test, 'iloc') else y_test[i]\n",
    "    \n",
    "    prob, level, color, rec = predict_heart_disease_risk(\n",
    "        patient, model, scaler, X.columns.tolist()\n",
    "    )\n",
    "    \n",
    "    actual_status = 'âŒ Has Heart Disease' if actual == 1 else 'âœ… No Heart Disease'\n",
    "    correct = \"âœ“\" if (prob >= 0.5 and actual == 1) or (prob < 0.5 and actual == 0) else \"âœ—\"\n",
    "    \n",
    "    print(f\"â”Œ{'â”€'*56}â”\")\n",
    "    print(f\"â”‚ ğŸ“‹ PATIENT {i+1:3d}                                          â”‚\")\n",
    "    print(f\"â”œ{'â”€'*56}â”¤\")\n",
    "    print(f\"â”‚ {color} Risk Level: {level:20s}                â”‚\")\n",
    "    print(f\"â”‚ Probability: {prob:5.1%}                                  â”‚\")\n",
    "    print(f\"â”‚ Actual: {actual_status:35s}     â”‚\")\n",
    "    print(f\"â”‚ Prediction: {correct}                                       â”‚\")\n",
    "    print(f\"â”‚ ğŸ“ {rec[:50]:50s} â”‚\")\n",
    "    print(f\"â””{'â”€'*56}â”˜\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“ˆ STRATIFIED K-FOLD CROSS-VALIDATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Create pipeline (proper way - fit scaler on each fold's training data only)\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Get full data (unscaled)\n",
    "X_full = df.drop('target', axis=1)\n",
    "y_full = (df['target'] == '2').astype(int)\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate multiple metrics\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "print(\"ğŸ“Š 5-FOLD STRATIFIED CROSS-VALIDATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results = {}\n",
    "for metric in metrics:\n",
    "    scores = cross_val_score(pipeline, X_full, y_full, cv=cv, scoring=metric)\n",
    "    results[metric] = scores\n",
    "    print(f\"{metric.upper():12}: {scores.mean():.4f} Â± {scores.std():.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(10, 6))\n",
    "positions = np.arange(len(metrics))\n",
    "means = [results[m].mean() for m in metrics]\n",
    "stds = [results[m].std() for m in metrics]\n",
    "\n",
    "bars = plt.bar(positions, means, yerr=stds, capsize=5, \n",
    "               color=['steelblue', 'coral', 'green', 'purple', 'gold'],\n",
    "               edgecolor='black', linewidth=1.5)\n",
    "plt.xticks(positions, [m.upper() for m in metrics], fontsize=11)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Cross-Validation Results (5-Fold Stratified)\\nError bars show Â±1 std dev', fontsize=14)\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, mean, std in zip(bars, means, stds):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.02,\n",
    "             f'{mean:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ These confidence intervals help us understand model reliability!\")\n",
    "print(\"   Low variance = consistent performance across folds\")\n",
    "print(\"   High variance = model may be sensitive to data splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âš–ï¸ THRESHOLD OPTIMIZATION FOR MEDICAL DIAGNOSIS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Get precision-recall curve\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "# Calculate F1 and F2 (F2 weights recall more heavily)\n",
    "f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-10)\n",
    "f2_scores = 5 * (precision[:-1] * recall[:-1]) / (4 * precision[:-1] + recall[:-1] + 1e-10)\n",
    "\n",
    "# Find optimal thresholds\n",
    "optimal_f1_idx = np.argmax(f1_scores)\n",
    "optimal_f2_idx = np.argmax(f2_scores)\n",
    "\n",
    "# For medical: we want high recall (catch all cases)\n",
    "# Find threshold where recall >= 0.9\n",
    "high_recall_idx = np.where(recall[:-1] >= 0.9)[0]\n",
    "if len(high_recall_idx) > 0:\n",
    "    medical_threshold = thresholds_pr[high_recall_idx[-1]]\n",
    "else:\n",
    "    medical_threshold = 0.3\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Precision-Recall Curve\n",
    "ax = axes[0]\n",
    "ax.plot(recall, precision, 'b-', linewidth=2)\n",
    "ax.scatter(recall[optimal_f1_idx], precision[optimal_f1_idx], \n",
    "          color='red', s=100, label=f'Best F1 (thresh={thresholds_pr[optimal_f1_idx]:.2f})')\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Precision', fontsize=12)\n",
    "ax.set_title('Precision-Recall Curve', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Metrics vs Threshold\n",
    "ax = axes[1]\n",
    "ax.plot(thresholds_pr, f1_scores, 'g-', linewidth=2, label='F1 Score')\n",
    "ax.plot(thresholds_pr, f2_scores, 'b-', linewidth=2, label='F2 Score (recall-heavy)')\n",
    "ax.plot(thresholds_pr, recall[:-1], 'r-', linewidth=2, label='Recall')\n",
    "ax.axvline(x=0.5, color='gray', linestyle='--', alpha=0.5, label='Default (0.5)')\n",
    "ax.axvline(x=medical_threshold, color='red', linestyle='--', \n",
    "          label=f'Medical (90% recall): {medical_threshold:.2f}')\n",
    "ax.set_xlabel('Threshold', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Metrics vs Threshold', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare predictions at different thresholds\n",
    "print(\"ğŸ“Š THRESHOLD COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "for thresh, name in [(0.5, 'Default (0.5)'), (medical_threshold, f'Medical ({medical_threshold:.2f})')]:\n",
    "    y_pred_t = (y_proba >= thresh).astype(int)\n",
    "    tp = np.sum((y_test == 1) & (y_pred_t == 1))\n",
    "    fn = np.sum((y_test == 1) & (y_pred_t == 0))\n",
    "    fp = np.sum((y_test == 0) & (y_pred_t == 1))\n",
    "    recall_t = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    precision_t = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    f1_t = 2 * precision_t * recall_t / (precision_t + recall_t) if (precision_t + recall_t) > 0 else 0\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"   Recall: {recall_t:.3f} (catching {tp}/{tp+fn} sick patients)\")\n",
    "    print(f\"   Precision: {precision_t:.3f}\")\n",
    "    print(f\"   F1: {f1_t:.3f}\")\n",
    "    print(f\"   Missed Cases (FN): {fn}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ RECOMMENDATION: Use lower threshold in medical screening!\")\n",
    "print(\"   Better to have extra tests (FP) than miss a disease (FN)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Conclusion & Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Logistic Regression is ideal for medical diagnosis** because it provides interpretable coefficients\n",
    "2. **Probability outputs** help doctors make nuanced decisions (not just yes/no)\n",
    "3. **ROC-AUC is better than accuracy** for imbalanced medical data\n",
    "4. **Threshold tuning is CRITICAL** - in medicine, we prioritize recall to catch all cases\n",
    "5. **Cross-validation** gives us confidence in model reliability\n",
    "\n",
    "### Medical ML Best Practices\n",
    "\n",
    "| Aspect | Recommendation |\n",
    "|--------|---------------|\n",
    "| **Threshold** | Lower than 0.5 for screening (maximize recall) |\n",
    "| **Metrics** | Focus on Recall, F2-score, ROC-AUC |\n",
    "| **Validation** | Stratified K-Fold CV with multiple metrics |\n",
    "| **Interpretation** | Use coefficients to expother risk factors |\n",
    "| **Deployment** | Always include uncertainty estimates |\n",
    "\n",
    "### Ethical Considerations\n",
    "\n",
    "> *\"The goal of ML in healthcare is to AUGMENT human decision-making, not replace it.\"*\n",
    "\n",
    "- âœ… Help doctors prioritize high-risk patients\n",
    "- âœ… Provide second opinion for diagnosis\n",
    "- âŒ Never make final medical decisions autonomously\n",
    "- âŒ Never deploy without proper clinical validation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Validate on independent dataset\n",
    "2. Test across different patient populations\n",
    "3. Get clinical expert review\n",
    "4. Submit for regulatory approval (FDA, CE marking)\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've built a production-ready heart disease classifier! ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Production Checklist\n",
    "\n",
    "Before deploying any medical ML model:\n",
    "\n",
    "- [ ] **Data Quality**: Verify no data leakage, proper train/test split\n",
    "- [ ] **Clinical Validation**: Reviewed by domain experts\n",
    "- [ ] **Bias Testing**: Tested across demographics (age, sex, ethnicity)\n",
    "- [ ] **Threshold Calibration**: Optimized for clinical use case\n",
    "- [ ] **Expotherability**: Can expother predictions to clinicians\n",
    "- [ ] **Monitoring**: Track performance drift over time\n",
    "- [ ] **Regulatory**: Compliance with medical device regulations (FDA, CE)\n",
    "- [ ] **Documentation**: Complete model card and usage guidelines\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š Further Reading\n",
    "\n",
    "- **Scikit-learn**: [Logistic Regression Documentation](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)\n",
    "- **Medical ML**: \"Machine Learning in Healthcare\" by MIT\n",
    "- **Interpretability**: \"Interpretable Machine Learning\" by Christoph Molnar\n",
    "- **Regulatory**: FDA guidance on AI/ML-based Software as a Medical Device (SaMD)\n",
    "\n",
    "---\n",
    "\n",
    "*Built with â¤ï¸ for education | Not for clinical use without proper validation*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
