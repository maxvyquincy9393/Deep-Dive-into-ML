{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97230dfb",
   "metadata": {},
   "source": [
    "## The Three Multiclass Strategies\n",
    "\n",
    "**One-vs-Rest (OvR):** Train K binary classifiers, one for each class vs all others.\n",
    "- For K classes, train K classifiers\n",
    "- Classifier k: \"Is this class k or not?\"\n",
    "- Prediction: Pick class with highest confidence\n",
    "\n",
    "**One-vs-One (OvO):** Train a classifier for every pair of classes.\n",
    "- For K classes, train K(K-1)/2 classifiers\n",
    "- Each classifier distinguishes between exactly 2 classes\n",
    "- Prediction: Voting among all classifiers\n",
    "\n",
    "**Softmax (Multinomial):** Single model that outputs K probabilities.\n",
    "- Single classifier with K output nodes\n",
    "- Softmax function ensures probabilities sum to 1\n",
    "- Prediction: Class with highest probability\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4fc2e",
   "metadata": {},
   "source": [
    "## Experiment 1: Iris Classification\n",
    "\n",
    "Let's compare all three approaches on the classic Iris dataset (3 classes, 4 features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf24052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Iris Dataset:\")\n",
    "print(f\"  Classes: {list(class_names)}\")\n",
    "print(f\"  Samples: {X.shape[0]}, Features: {X.shape[1]}\")\n",
    "print(f\"  Train: {len(X_train)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all three multiclass strategies\n",
    "import time\n",
    "\n",
    "# One-vs-Rest\n",
    "start = time.time()\n",
    "ovr = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "ovr.fit(X_train, y_train)\n",
    "ovr_time = (time.time() - start) * 1000\n",
    "ovr_acc = ovr.score(X_test, y_test)\n",
    "\n",
    "# One-vs-One\n",
    "start = time.time()\n",
    "ovo = OneVsOneClassifier(LogisticRegression(max_iter=1000))\n",
    "ovo.fit(X_train, y_train)\n",
    "ovo_time = (time.time() - start) * 1000\n",
    "ovo_acc = ovo.score(X_test, y_test)\n",
    "\n",
    "# Softmax (Multinomial)\n",
    "start = time.time()\n",
    "softmax = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "softmax.fit(X_train, y_train)\n",
    "softmax_time = (time.time() - start) * 1000\n",
    "softmax_acc = softmax.score(X_test, y_test)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MULTICLASS STRATEGY COMPARISON ON IRIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'Strategy':<20} {'Accuracy':<15} {'Time (ms)':<15} {'# Classifiers'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'One-vs-Rest (OvR)':<20} {ovr_acc:.4f}         {ovr_time:.2f}           {len(ovr.estimators_)}\")\n",
    "print(f\"{'One-vs-One (OvO)':<20} {ovo_acc:.4f}         {ovo_time:.2f}           {len(ovo.estimators_)}\")\n",
    "print(f\"{'Softmax':<20} {softmax_acc:.4f}         {softmax_time:.2f}           1\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58302e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nINTERPRETATION:\")\n",
    "print(f\"\\n1. Number of Classifiers:\")\n",
    "print(f\"   - OvR: K = {len(class_names)} classifiers (one per class)\")\n",
    "print(f\"   - OvO: K(K-1)/2 = {len(class_names)}*{len(class_names)-1}/2 = {len(ovo.estimators_)} classifiers\")\n",
    "print(f\"   - Softmax: 1 unified model\")\n",
    "\n",
    "print(f\"\\n2. Training Complexity:\")\n",
    "print(f\"   - OvR: Each classifier sees ALL training data\")\n",
    "print(f\"   - OvO: Each classifier sees only data from 2 classes (smaller subsets)\")\n",
    "print(f\"   - Softmax: Single optimization over all data\")\n",
    "\n",
    "print(f\"\\n3. For Iris (3 classes, 150 samples):\")\n",
    "print(f\"   - All three perform similarly because classes are well-separated\")\n",
    "print(f\"   - Differences become more pronounced with more classes or overlap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c0e16",
   "metadata": {},
   "source": [
    "## Experiment 2: Decision Boundary Visualization\n",
    "\n",
    "Let's visualize how each strategy partitions the feature space. We'll use only 2 features for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa215500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only 2 features for visualization\n",
    "X_2d = X_scaled[:, :2]  # sepal length, sepal width\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(X_2d, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train models on 2D data\n",
    "ovr_2d = OneVsRestClassifier(LogisticRegression(max_iter=1000)).fit(X_train_2d, y_train_2d)\n",
    "ovo_2d = OneVsOneClassifier(LogisticRegression(max_iter=1000)).fit(X_train_2d, y_train_2d)\n",
    "softmax_2d = LogisticRegression(multi_class='multinomial', max_iter=1000).fit(X_train_2d, y_train_2d)\n",
    "\n",
    "# Create mesh grid for decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "print(\"Models trained on 2D features for visualization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a27bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision boundaries\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "models = [ovr_2d, ovo_2d, softmax_2d]\n",
    "titles = ['One-vs-Rest (OvR)', 'One-vs-One (OvO)', 'Softmax (Multinomial)']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "for ax, model, title in zip(axes, models, titles):\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
    "    ax.contour(xx, yy, Z, colors='black', linewidths=0.5)\n",
    "    \n",
    "    for i, (color, name) in enumerate(zip(['blue', 'green', 'red'], class_names)):\n",
    "        mask = y == i\n",
    "        ax.scatter(X_2d[mask, 0], X_2d[mask, 1], c=color, label=name, \n",
    "                   edgecolors='black', s=50, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Sepal Length (scaled)', fontsize=11)\n",
    "    ax.set_ylabel('Sepal Width (scaled)', fontsize=11)\n",
    "    ax.set_title(f'{title}\\nAccuracy: {model.score(X_test_2d, y_test_2d):.3f}', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"OBSERVATION:\")\n",
    "print(\"  - All three methods produce LINEAR decision boundaries (because base is Logistic Regression)\")\n",
    "print(\"  - OvR: Each boundary separates one class from the rest\")\n",
    "print(\"  - OvO: Boundaries emerge from voting among pairwise classifiers\")\n",
    "print(\"  - Softmax: Single unified model produces all boundaries simultaneously\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8ac49",
   "metadata": {},
   "source": [
    "## Experiment 3: Scaling to More Classes\n",
    "\n",
    "Let's see how the methods compare as we increase the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff103a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scaling behavior\n",
    "n_classes_list = [3, 5, 7, 10]\n",
    "results = []\n",
    "\n",
    "for n_classes in n_classes_list:\n",
    "    # Generate synthetic data\n",
    "    X_synth, y_synth = make_classification(n_samples=500, n_features=10, n_informative=8,\n",
    "                                            n_classes=n_classes, n_clusters_per_class=1,\n",
    "                                            random_state=42)\n",
    "    X_synth = StandardScaler().fit_transform(X_synth)\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_synth, y_synth, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # OvR\n",
    "    start = time.time()\n",
    "    ovr = OneVsRestClassifier(LogisticRegression(max_iter=1000)).fit(X_tr, y_tr)\n",
    "    ovr_t = (time.time() - start) * 1000\n",
    "    \n",
    "    # OvO\n",
    "    start = time.time()\n",
    "    ovo = OneVsOneClassifier(LogisticRegression(max_iter=1000)).fit(X_tr, y_tr)\n",
    "    ovo_t = (time.time() - start) * 1000\n",
    "    \n",
    "    # Softmax\n",
    "    start = time.time()\n",
    "    smax = LogisticRegression(multi_class='multinomial', max_iter=1000).fit(X_tr, y_tr)\n",
    "    smax_t = (time.time() - start) * 1000\n",
    "    \n",
    "    results.append({\n",
    "        'K': n_classes,\n",
    "        'OvR_clf': n_classes,\n",
    "        'OvO_clf': n_classes * (n_classes - 1) // 2,\n",
    "        'OvR_time': ovr_t,\n",
    "        'OvO_time': ovo_t,\n",
    "        'Softmax_time': smax_t,\n",
    "        'OvR_acc': ovr.score(X_te, y_te),\n",
    "        'OvO_acc': ovo.score(X_te, y_te),\n",
    "        'Softmax_acc': smax.score(X_te, y_te)\n",
    "    })\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SCALING COMPARISON: Number of Classes vs Performance\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'K':<5} {'OvR clf':<10} {'OvO clf':<10} {'OvR acc':<10} {'OvO acc':<10} {'Softmax acc'}\")\n",
    "print(\"-\" * 70)\n",
    "for r in results:\n",
    "    print(f\"{r['K']:<5} {r['OvR_clf']:<10} {r['OvO_clf']:<10} {r['OvR_acc']:<10.3f} {r['OvO_acc']:<10.3f} {r['Softmax_acc']:.3f}\")\n",
    "\n",
    "print(\"\\nKEY INSIGHT:\")\n",
    "print(\"  OvO classifier count grows as K(K-1)/2 - quadratic!\")\n",
    "print(\"  For K=10: OvO needs 45 classifiers vs OvR's 10\")\n",
    "print(\"  Softmax scales best: always just 1 model regardless of K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea767b0c",
   "metadata": {},
   "source": [
    "## When to Use Which Strategy?\n",
    "\n",
    "| Scenario | Recommended | Why |\n",
    "|----------|-------------|-----|\n",
    "| Few classes (K < 5) | **Any** | All perform similarly |\n",
    "| Many classes (K > 10) | **Softmax** or **OvR** | OvO has too many classifiers |\n",
    "| Binary classifiers are expensive | **Softmax** | Single model |\n",
    "| Classes are imbalanced | **OvO** | Each classifier sees balanced subsets |\n",
    "| Need probability outputs | **Softmax** | Natural probability interpretation |\n",
    "| Using non-probabilistic base (SVM) | **OvR** or **OvO** | Standard approaches for SVM |\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**One-vs-Rest (OvR):**\n",
    "- Train K binary classifiers\n",
    "- Each sees all data (can be slow for large datasets)\n",
    "- May have ambiguous regions\n",
    "\n",
    "**One-vs-One (OvO):**\n",
    "- Train K(K-1)/2 classifiers\n",
    "- Each sees only subset of data (faster per classifier)\n",
    "- Voting can resolve ties\n",
    "\n",
    "**Softmax:**\n",
    "- Single unified model\n",
    "- Scales best with number of classes\n",
    "- Outputs proper probabilities"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
